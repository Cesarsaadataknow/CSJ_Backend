# -----------------------------------------------------------------------------
# IMPORTACIONES
# -----------------------------------------------------------------------------
import json
import uuid
from typing import Optional, List
from fastapi import UploadFile, HTTPException
from dotenv import load_dotenv, find_dotenv
from langchain_openai import AzureChatOpenAI
from langchain.agents import initialize_agent, Tool
from langchain.agents.agent_types import AgentType
from app.config import settings
from helpers.tools import Tools
from core.ai_services import AIServices
from helpers.prompts import system_prompt_agente

load_dotenv(find_dotenv(), override=True)

MAX_CONVERSATIONS_PER_USER = 10
MAX_FILES_PER_SESSION = 40


class Orchestrator:
    def __init__(self):
        self.llm = AzureChatOpenAI(
            api_key=settings.AZURE_OPENAI_KEY,
            azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
            api_version=settings.AZURE_OPENAI_OPENAI_VERSION,
            deployment_name=settings.AZURE_OPENAI_CHAT_DEPLOYMENT,
            temperature=0.4,
        )

        self.tools_class = Tools()
        self.cosmosdb = AIServices.AzureCosmosDB()

        self.tools = [
            Tool.from_function(
                func=self.tools_class.tool_rag,
                name="tool_rag",
                description=(
                    "Usa esta herramienta SIEMPRE que haya documentos cargados "
                    "o cuando el usuario solicite an치lisis jur칤dico."
                ),
            ),
            Tool.from_function(
                func=self.tools_class.tool_conversacional,
                name="tool_conversacional",
                description="Saludos y mensajes cortos."
            ),
        ]

        self.agent = initialize_agent(
            tools=self.tools,
            llm=self.llm,
            agent=AgentType.OPENAI_FUNCTIONS,
            verbose=True,
            handle_parsing_errors=True,
            agent_kwargs={"system_message": system_prompt_agente},
        )

    # -------------------------------------------------------------------------
    def ejecutar_agente(
        self,
        mensaje_usuario: str,
        user_id: str,
        session_id: Optional[str] = None,
        files: Optional[List[UploadFile]] = None,
    ) -> dict:

        if not user_id:
            raise HTTPException(status_code=401, detail="Usuario no autenticado")

        if not session_id:
            session_id = str(uuid.uuid4())

        # 游녤 Vincular contexto (ESTO ES CLAVE)
        self.tools_class.bind_context(
            session_id=session_id,
            user_id=user_id,
            files=files
        )

        # ---------------------------------------------------------------------
        # HISTORIAL
        # ---------------------------------------------------------------------
        historial = self.cosmosdb.get_session_messages(session_id)
        contexto = "Historial de la sesi칩n:\n\n"

        for m in historial:
            contexto += f"<usuario>: {m.get('UserQuestion','')}\n"
            contexto += f"<asistente>: {m.get('IAResponse','')}\n"

        input_modelo = f"""
{contexto}

El usuario puede haber cargado documentos.
Si hay documentos, debes analizarlos usando tool_rag.

<usuario>: {mensaje_usuario}
<asistente>:
"""

        # ---------------------------------------------------------------------
        # EJECUCI칍N AGENTE
        # ---------------------------------------------------------------------
        respuesta = self.agent.invoke({"input": input_modelo})
        output = respuesta.get("output", "").strip()

        # ---------------------------------------------------------------------
        # GUARDAR RESPUESTA
        # ---------------------------------------------------------------------
        self.cosmosdb.save_message_chat(
            session_id=session_id,
            user_id=user_id,
            user_question=mensaje_usuario,
            ia_response=output,
            channel="web",
            extra={"tools": str(respuesta.get("intermediate_steps"))},
        )

        # ---------------------------------------------------------------------
        # DETECTAR INTENCI칍N DE WORD (backend decide)
        # ---------------------------------------------------------------------
        quiere_word = any(
            k in mensaje_usuario.lower()
            for k in ["word", "docx", "descargar", "documento"]
        )

        if quiere_word:
            return {
                "reply_text": (
                    "El an치lisis jur칤dico ya fue realizado. "
                    "쮺onfirmas que deseas descargarlo en formato Word?"
                ),
                "session_id": session_id,
            }

        return {
            "reply_text": output,
            "session_id": session_id,
        }



# # -----------------------------------------------------------------------------
# # region            IMPORTACIONES
# # -----------------------------------------------------------------------------
# import json
# import uuid
# from typing import Optional, List
# from fastapi import UploadFile, HTTPException
# from dotenv import load_dotenv, find_dotenv
# from langchain_openai import AzureChatOpenAI
# from langchain.agents import initialize_agent, Tool
# from langchain.agents.agent_types import AgentType
# from app.config import settings
# from helpers.tools import Tools
# from core.ai_services import AIServices
# from helpers.prompts import system_prompt_agente
# #endregion


# # -----------------------------------------------------------------------------
# # region           FUNCION EXTRACCION DE VARIABLES
# # -----------------------------------------------------------------------------
# load_dotenv(find_dotenv(), override=True)
# #endregion


# # -----------------------------------------------------------------------------
# # region           VALORES PARA CONDICIONES (cONVERSACIONES Y DOCUMENTOS)
# # -----------------------------------------------------------------------------
# MAX_CONVERSATIONS_PER_USER = 10
# MAX_FILES_PER_SESSION = 40
# #endregion


# # -----------------------------------------------------------------------------
# # region           AGENTE:EJECUCION E HISTORIAL - CONTEXTO
# # -----------------------------------------------------------------------------
# class Orchestrator:
#     def __init__(self):
#         self.llm = AzureChatOpenAI(
#             api_key=settings.AZURE_OPENAI_KEY,
#             azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
#             api_version=settings.AZURE_OPENAI_OPENAI_VERSION,
#             deployment_name=settings.AZURE_OPENAI_CHAT_DEPLOYMENT,
#             temperature=0.7,
#         )

#         # ----------------------------
#         # Clases
#         # ----------------------------
#         self.tools_class = Tools()
#         self.cosmosdb = AIServices.AzureCosmosDB()


#         # ----------------------------
#         # Tools
#         # ----------------------------
#         self.tools = [
#             Tool.from_function(
#                 func=self.tools_class.tool_rag,
#                 name="tool_rag",
#                 description=(
#                     "Usa esta tool para responder preguntas jur칤dicas basadas en los documentos "
#                     "indexados y/o documentos cargados por el usuario (RAG)."
#                 ),
#             ),
#             Tool.from_function(
#                 func=self.tools_class.tool_conversacional,
#                 name="tool_conversacional",
#                 description=(
#                     "Responde saludos o mensajes cortos de cortes칤a como 'hola', 'gracias', "
#                     "'buenos d칤as', 'c칩mo est치s', etc. Si el usuario adjunta documentos y no pide "
#                     "nada espec칤fico, gu칤a preguntando qu칠 desea hacer con ellos."
#                 ),
#             ),
#         ]

#         system_prompt = system_prompt_agente

#         self.agent = initialize_agent(
#             tools=self.tools,
#             llm=self.llm,
#             agent=AgentType.OPENAI_FUNCTIONS,
#             verbose=True,
#             handle_parsing_errors=True,
#             agent_kwargs={"system_message": system_prompt},
#         )

#     # ----------------------------
#     # AGENTE
#     # ----------------------------
#     def ejecutar_agente(
#         self,
#         mensaje_usuario: str,
#         user_id: str,
#         session_id: Optional[str] = None,
#         files: Optional[List[UploadFile]] = None,
#     ) -> dict:

#         # ----------------------------
#         # Validaci칩n usuario
#         # ----------------------------
#         if not user_id:
#             raise HTTPException(status_code=401, detail="Usuario no autenticado.")

#         # ----------------------------
#         # L칤mite 10 conversaciones
#         # ----------------------------
#         if not session_id:
#             user_sessions = self.cosmosdb.get_user_sessions(user_id)
#             if len(user_sessions) >= MAX_CONVERSATIONS_PER_USER:
#                 raise HTTPException(
#                     status_code=409,
#                     detail=(
#                         f"L칤mite alcanzado: m치ximo {MAX_CONVERSATIONS_PER_USER} conversaciones por usuario. "
#                         "Por favor elimina una conversacion del panel izquierdo para crear una nueva."
#                     ),
#                 )
#             session_id = str(uuid.uuid4())

#         # ----------------------------
#         # L칤mite 40 documentos por sesi칩n
#         # ----------------------------
#         if files:
#             existing_files = self.cosmosdb.count_uploaded_files(session_id)
#             if existing_files + len(files) > MAX_FILES_PER_SESSION:
#                 raise HTTPException(
#                     status_code=409,
#                     detail=(
#                         f"L칤mite alcanzado: m치ximo {MAX_FILES_PER_SESSION} documentos por sesi칩n. "
#                         f"Ya hay {existing_files} y est치s intentando subir {len(files)}."
#                     ),
#                 )
            
#         # ----------------------------
#         # Generacion de historial y contexto de agente
#         # ----------------------------    

#         self.tools_class.bind_context(session_id=session_id, user_id=user_id, files=files)
#         historial = self.cosmosdb.get_session_messages(session_id)
#         contexto = (
#             "Historial de la sesi칩n (usa esto para mantener continuidad):\n\n"
#         )
#         for mensaje in historial:
#             uq = (mensaje.get("UserQuestion") or "").strip()
#             ar = mensaje.get("IAResponse")
#             if isinstance(ar, dict):
#                 ar = json.dumps(ar, ensure_ascii=False)  
#             ar = (ar or "").strip()
#             contexto += f"<usuario>: {uq}\n<asistente>: {ar}\n"
#         input_modelo = f"{contexto}<usuario>: {mensaje_usuario}\n<asistente>:"

#         # ----------------------------
#         # Ejecucion de agente
#         # ----------------------------    

#         respuesta = self.agent.invoke({"input": input_modelo})
#         output = (respuesta.get("output") or "").replace("**", "").strip()
#         self.cosmosdb.save_message_chat(
#             session_id=session_id,
#             user_id=user_id,
#             user_question=mensaje_usuario,
#             ia_response=output,
#             channel="web",
#             extra={"tool_used": str(respuesta.get("intermediate_steps", ""))},
#         )

#         return {"reply_text": output, "session_id": session_id}
# # endregion